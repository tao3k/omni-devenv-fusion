# Justfile for omni-dev-fusion project  
# https://github.com/casey/just
#
# Design principles:
# - Interactive commands for humans (e.g., `just commit`)
# - Agent-friendly commands with `agent-*` prefix (e.g., `just agent-commit "feat" "cli" "message"`)
# - SRE health checks with JSON output for machine parsing
# - Group annotations for clean `just --list` output

# ==============================================================================
# Global Settings
# ==============================================================================

set dotenv-load := true
set shell := ["bash", "-uc"]
set positional-arguments := true

# Enable JSON output mode via environment variable
json_output := if env_var_or_default("JUST_JSON", "false") == "true" { "true" } else { "false" }

# ==============================================================================
# Core Commands
# ==============================================================================

default:
    @just --list

# ==============================================================================
# AGENT INTERFACE (Non-interactive, argument-based)
# Designed for AI agents - accepts parameters, no interactive prompts
# ==============================================================================

# Non-interactive commit for agents
# Usage: just agent-commit
# Reads commit message from token file generated by smart_commit MCP tool
agent-commit:
    #!/usr/bin/env bash
    set -euo pipefail

    # Token file path (must match commit.py)
    TOKEN_FILE="/tmp/.omni_commit_token"

    # Check if token exists and is valid (only from smart_commit workflow)
    if [ ! -f "$TOKEN_FILE" ]; then
        echo "Error: No authorization token found." >&2
        echo "" >&2
        echo "To commit, you must:" >&2
        echo "1. Use the smart_commit MCP tool first: @omni-orchestrator smart_commit(context='...')" >&2
        echo "2. Then run: just agent-commit" >&2
        exit 1
    fi

    # Read token content: format is session_id:token:timestamp:message
    TOKEN_CONTENT=$(cat "$TOKEN_FILE")
    SESSION_ID=$(echo "$TOKEN_CONTENT" | cut -d':' -f1)
    TOKEN=$(echo "$TOKEN_CONTENT" | cut -d':' -f2)
    TIMESTAMP=$(echo "$TOKEN_CONTENT" | cut -d':' -f3)
    # Message may contain colons, so use the 4th field to end
    MSG=$(echo "$TOKEN_CONTENT" | cut -d':' -f4-)

    # Validate token is not empty
    if [ -z "$TOKEN" ]; then
        echo "Error: Invalid authorization token (empty)." >&2
        rm -f "$TOKEN_FILE"
        exit 1
    fi

    # Check token expiration (5 minutes)
    TOKEN_EPOCH=$(date -d "$TIMESTAMP" +%s 2>/dev/null || date +%s)
    NOW_EPOCH=$(date +%s)
    ELAPSED=$((NOW_EPOCH - TOKEN_EPOCH))
    if [ $ELAPSED -gt 300 ]; then
        echo "Error: Authorization token has expired." >&2
        rm -f "$TOKEN_FILE"
        exit 1
    fi

    echo "Commit message: $MSG"
    echo ""

    # Run lefthook first to apply all formatting fixes (prevents unstaged files after commit)
    echo "Running pre-commit hooks..."
    lefthook run pre-commit --all-files --no-tty

    # Re-stage all files after formatting (prettier modifies files but doesn't auto-stage)
    echo "Re-staging all modified files..."
    git add -A

    # Run tests before commit
    echo "Running tests..."
    devenv test

    # Stage again after tests (in case tests modify files)
    echo "Staging all files..."
    git add -A

    # Commit with staged changes
    git commit -m "$MSG"

    # Consume the token (invalidate it)
    rm -f "$TOKEN_FILE"

    echo ""
    echo "Committed: $MSG"

# Agent-friendly validate (non-interactive)
agent-validate:
    @echo "Running validation..." && lefthook run pre-commit && devenv test

# Agent-friendly validate with git status output (safe - no commit)
# Usage: just agent-test-status
# This command runs tests and outputs git status for agent to read
agent-test-status:
    #!/usr/bin/env bash
    set -euo pipefail
    echo "=== TEST_START ==="
    devenv test
    TEST_RESULT=$?
    echo "=== TEST_END ==="
    echo "=== GIT_STATUS_START ==="
    git status --short
    echo "=== GIT_STATUS_END ==="
    echo "=== GIT_LOG_START ==="
    git log --oneline -3
    echo "=== GIT_LOG_END ==="
    if [ $TEST_RESULT -eq 0 ]; then
        echo "Tests passed"
    else
        echo "Tests failed"
    fi
    exit $TEST_RESULT

# Agent-friendly format (apply fixes)
agent-fmt:
    @echo "Applying formatting fixes..." && lefthook run pre-commit --all-files --no-tty

# Agent-friendly version bump
agent-bump type="auto":
    #!/usr/bin/env bash
    set -euo pipefail
    BUMP_TYPE="{{type}}"
    if [ "$BUMP_TYPE" = "auto" ]; then
        cog bump --auto
    else
        cog bump --$BUMP_TYPE
    fi

# Agent-friendly release publish
agent-publish-release version="latest":
    #!/usr/bin/env bash
    set -euo pipefail
    VERSION="{{version}}"
    if [ "$VERSION" = "latest" ]; then
        VERSION=$(git describe --tags --abbrev=0)
    fi
    NOTES=$(mktemp)
    just release-notes "$VERSION" > "$NOTES"
    gh release create "$VERSION" --title "Release $VERSION" --notes-file "$NOTES" --verify-tag
    rm -f "$NOTES"

# Agent-friendly complete release workflow
agent-release type="auto" version="latest":
    #!/usr/bin/env bash
    set -euo pipefail
    just agent-validate
    just agent-bump {{type}}
    just agent-publish-release {{version}}

# ==============================================================================
# ðŸ¤– AGENT WORKFLOW AUTOMATION
# ==============================================================================

# Generate high-density context dump for agent startup
[no-exit-message]
agent-context:
    @echo "<project_context_dump>"
    @echo "=== ðŸ“‹ CURRENT MISSION (Backlog Top 20) ==="
    @head -n 20 Backlog.md 2>/dev/null || echo "âš ï¸ No Backlog.md found. Create one to drive the agent."
    @echo ""
    @echo "=== ðŸš¦ GIT STATUS ==="
    @git status --short --branch
    @echo ""
    @echo "=== âš™ï¸ RULES (cog.toml scopes) ==="
    @grep -A 20 "scopes =" cog.toml 2>/dev/null | head -15 || echo "cog.toml not found"
    @echo ""
    @echo "=== ðŸ“ RECENT COMMITS ==="
    @git log --oneline -5
    @echo ""
    @echo "=== âœï¸ WRITING STYLE (agent/writing-style/) ==="
    @ls -1 agent/writing-style/*.md 2>/dev/null | xargs -I {} basename {} .md | sed 's/^/  - /' || echo "  No style guides found"
    @echo "  Hint: Use 'writer.polish_text' to enforce these rules"
    @echo ""
    @echo "</project_context_dump>"
    @echo ""
    @echo "ðŸ’¡ INSTRUCTION: Read the context above. Identify the active task from Backlog.md and check if it aligns with git status. Await user command."

# ==============================================================================
# ðŸ§  COGNITION & SPECS
# ==============================================================================

# Focus Mode: Load specific Spec and prepare for development
# Usage: just agent-focus assets/specs/feature_name.md
agent-focus spec_path:
    @echo "ðŸš€ Focusing Agent on Spec: {{spec_path}}..."
    @echo ""
    @echo "=== ðŸŽ¯ FOCUS TARGET: {{spec_path}} ==="
    @cat {{spec_path}}
    @echo ""
    @echo "=== ðŸ—ï¸ RELATED CODE STRUCTURE ==="
    @echo "packages/python/agent modules:"
    @ls -1 packages/python/agent/src/agent/*.py 2>/dev/null | xargs -I {} basename {} .py | sed 's/^/  - /' || echo "  No modules found"
    @echo "agent/skills modules:"
    @ls -1 agent/skills/ 2>/dev/null | grep -v "^_" | sed 's/^/  - /' || echo "  No skills found"
    @echo ""
    @echo "=== ðŸ“‹ BACKLOG ALIGNMENT ==="
    @grep -i "$(basename {{spec_path}} .md)" Backlog.md 2>/dev/null || echo "  No matching backlog entry found"
    @echo ""
    @echo "ðŸ’¡ INSTRUCTION: Review the Spec above. Create a PLAN in 'SCRATCHPAD.md' before modifying any code."
    @echo "SCRATCHPAD Location: .cache/omni-dev-fusion/.memory/active_context/SCRATCHPAD.md"

# Quick create new Spec from template
# Usage: just spec-new "feature_name" "Feature description..."
spec-new name description:
    @echo "ðŸ—ï¸ Scaffolding Spec: {{name}}..."
    @cp assets/specs/template.md assets/specs/{{name}}.md
    @( \
        echo "=== ðŸ“ TASK: DRAFT SPEC ==="; \
        echo "Target File: assets/specs/{{name}}.md"; \
        echo "Feature Name: {{name}}"; \
        echo "User Description: {{description}}"; \
        echo ""; \
        echo "ðŸ’¡ INSTRUCTION: Read the 'Target File' template. Fill in Sections 1 (Context) and 2 (Architecture) based on the 'User Description'. Leave Section 3 (Plan) for later."; \
    ) | claude
    @echo "âœ… Spec draft created at assets/specs/{{name}}.md"

# Start Claude with automatic context injection
agent-start:
    @echo "ðŸš€ Initializing Agent with Context..."
    @just agent-context | claude

# ==============================================================================
# HUMAN INTERFACE (Interactive commands preserved)
# Commands with user prompts for manual operations
# ==============================================================================

# Interactive commit helper (for humans - uses select/read)
[group('git')]
commit:
    #!/usr/bin/env bash
    set -euo pipefail
    echo "Interactive Conventional Commit"
    echo "================================"
    select TYPE in feat fix docs style refactor perf test build ci chore; do
        [ -n "$TYPE" ] && break
    done
    read -p "Enter scope (optional): " SCOPE
    SCOPE_STR=""
    if [ -n "$SCOPE" ]; then
        SCOPE_STR="($SCOPE)"
    fi
    read -p "Enter short description: " DESC
    read -p "Add detailed body? [y/N]: " -n 1 ADD_BODY
    echo
    BODY=""
    if [[ $ADD_BODY =~ ^[Yy]$ ]]; then
        echo "Enter body (Ctrl+D when done):"
        BODY=$(cat)
    fi
    read -p "Breaking change? [y/N]: " -n 1 BREAKING
    echo
    FOOTER=""
    if [[ $BREAKING =~ ^[Yy]$ ]]; then
        read -p "Describe breaking change: " BREAKING_DESC
        FOOTER="BREAKING CHANGE: $BREAKING_DESC"
    fi
    MSG="$TYPE$SCOPE_STR: $DESC"
    if [ -n "$BODY" ]; then
        MSG="$MSG\n\n$BODY"
    fi
    if [ -n "$FOOTER" ]; then
        MSG="$MSG\n\n$FOOTER"
    fi
    echo ""
    echo "Preview:"
    echo -e "$MSG"
    echo ""
    read -p "Commit? [Y/n]: " -n 1 CONFIRM
    echo
    if [[ ! $CONFIRM =~ ^[Nn]$ ]]; then
        git commit -m "$(echo -e "$MSG")"
        echo "Committed!"
    else
        echo "Cancelled"
        exit 1
    fi

# ==============================================================================
# SETUP & VALIDATION
# ==============================================================================

[group('setup')]
setup:
    @echo "ðŸš€ Setting up development environment..."
    @echo ""
    @echo "Step 1/3: Checking secrets configuration..."
    -@secretspec check --profile development 2>/dev/null || true
    @if ! secretspec check --profile development >/dev/null 2>&1; then \
        echo "âš ï¸  Secrets not configured."; \
        echo "   Checking if claude module needs to be disabled..."; \
        if grep -q "^    nixosModules.claude$" devenv.nix; then \
            echo "   Disabling claude module for initial setup..."; \
            sed -i '' 's/^    nixosModules.claude$/    # nixosModules.claude  # Disabled: configure secrets first/g' devenv.nix; \
            echo "   âœ… claude module disabled."; \
        else \
            echo "   âœ… claude module already disabled."; \
        fi; \
        echo ""; \
        echo "Step 2/3: Activating direnv (without claude module)..."; \
        direnv allow 2>/dev/null || true; \
        echo ""; \
        echo "Step 3/3: Environment ready (limited mode)."; \
        echo ""; \
        echo "ðŸ“ Next steps:"; \
        echo "   1. Configure secrets: https://secretspec.dev/concepts/providers/"; \
        echo "   2. Verify: just secrets-check"; \
        echo "   3. Re-run: just setup"; \
        echo ""; \
        echo "Run 'just' to see available commands."; \
    else \
        echo "âœ… Secrets OK!"; \
        echo ""; \
        echo "Step 2/3: Restoring claude module if needed..."; \
        if grep -q "^    # nixosModules.claude  # Disabled:" devenv.nix; then \
            sed -i '' 's/^    # nixosModules.claude  # Disabled:/    nixosModules.claude/g' devenv.nix; \
            echo "   âœ… claude module restored!"; \
        else \
            echo "   âœ… claude module already enabled."; \
        fi; \
        echo ""; \
        echo "Step 3/3: Activating direnv..."; \
        direnv allow; \
        echo ""; \
        echo "ðŸŽ‰ Environment fully ready!"; \
        echo ""; \
        echo "Run 'just' to see available commands."; \
    fi

[group('validate')]
validate: check-format check-commits lint test
    @echo "All validation checks passed!"

[group('validate')]
check-format:
    @echo "Checking code formatting..."
    @lefthook run pre-commit --all-files

[group('validate')]
lint:
    @echo "Linting files..."
    @lefthook run pre-commit

[group('validate')]
rust-check:
    @echo "Running Rust compile checks..."
    @cargo check --workspace --all-targets

[group('validate')]
rust-lint-inheritance-check:
    #!/usr/bin/env bash
    set -euo pipefail
    echo "Checking Rust crate lint inheritance..."
    missing="$(for f in packages/rust/crates/*/Cargo.toml; do if ! rg -q '^\[lints\]' "$f"; then echo "$f"; fi; done)"
    if [ -n "$missing" ]; then
        echo "Missing [lints] workspace = true in:"
        echo "$missing"
        exit 1
    fi
    echo "All Rust crates inherit workspace lint policy."

[group('validate')]
rust-clippy:
    @echo "Running Rust clippy baseline (lint-ready crate set, warnings denied)..."
    @cargo clippy -p omni-types -p omni-events -p omni-tokenizer -p omni-window -p omni-security -p omni-io -p omni-executor -p omni-mcp-client -p omni-ast -p omni-macros -p omni-lance -p omni-scanner -- -D warnings

[group('validate')]
rust-nextest:
    @echo "Running Rust tests via cargo-nextest..."
    @if ! command -v cargo-nextest >/dev/null 2>&1; then \
        echo "cargo-nextest is required but not installed."; \
        echo "Install with: nix profile add nixpkgs#cargo-nextest"; \
        exit 1; \
    fi
    @cargo nextest run --workspace --no-fail-fast

[group('validate')]
rust-quality-gate: rust-lint-inheritance-check rust-check rust-clippy rust-nextest
    @echo "Rust quality gates passed (check + strict clippy baseline + nextest)."

[group('validate')]
rust-test-snapshots:
    @echo "Running Rust snapshot contract tests..."
    @cargo test -p omni-vector --test test_fusion_snapshots

# KG cache (xiuxian-wendao) and search cache (omni-vector) unit tests
[group('validate')]
rust-test-cache:
    @echo "Running Rust cache tests (test_kg_cache, test_search_cache)..."
    @cargo test -p xiuxian-wendao --test test_kg_cache -- --test-threads=1
    @cargo test -p omni-vector --test test_search_cache -- --test-threads=1

# omni-agent: config, session, MCP, gateway (HTTP 400/404), agent loop
[group('validate')]
rust-test-agent:
    @echo "Running Rust agent tests (omni-agent)..."
    @cargo test -p omni-agent

# Regenerate Tantivy vs Lance FTS decision report from v4_large snapshot
# See docs/testing/keyword-backend-decision.md for full loop (snapshots + report).
[group('validate')]
keyword-backend-report:
    @echo "Regenerating keyword backend decision report (v4_large)..."
    @uv run python scripts/generate_keyword_backend_decision_report.py
    @echo "Wrote docs/testing/keyword-backend-decision-report.md"

# Regenerate statistical comparison (bootstrap CI, sign test, per-scene winner)
[group('validate')]
keyword-backend-statistical:
    @echo "Regenerating keyword backend statistical report (v4_large)..."
    @uv run python scripts/generate_keyword_backend_statistical_report.py
    @echo "Wrote docs/testing/keyword-backend-statistical-report.md"

[group('validate')]
test:
    @echo "TEST PIPELINE"
    @echo "========================================"
    @echo "[1/5] Rust compile gate"
    @just rust-check
    @echo ""
    @echo "[2/5] Rust snapshot contract gate"
    @just rust-test-snapshots
    @echo ""
    @echo "[3/5] Rust cache tests (kg_cache, search_cache)"
    @just rust-test-cache
    @echo ""
    @echo "[4/5] Rust agent tests (omni-agent)"
    @just rust-test-agent
    @echo ""
    @echo "[5/5] Python test suites"
    @uv run pytest packages/python/foundation/tests/ packages/python/core/tests/ \
        -v --tb=short
    @echo ""
    @uv run pytest packages/python/agent/tests/unit/cli/ \
        -v --tb=short
    @echo ""
    @cd packages/python/mcp-server && uv run pytest tests/ \
        -v --tb=short --ignore=tests/integration/test_sse.py \
        --ignore=tests/unit/test_interfaces.py \
        --ignore=tests/unit/test_types.py \
        --ignore=tests/unit/test_transport/test_sse.py
    @echo ""
    @echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    @echo "                              COMPLETE"
    @echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

[group('validate')]
test-quick:
    @echo "TEST PIPELINE (QUICK)"
    @echo "========================================"
    @uv run pytest packages/python/foundation/tests/ packages/python/core/tests/ packages/python/agent/tests/unit/cli/ -q --tb=short
    @cd packages/python/mcp-server && uv run pytest tests/ -q --tb=short --ignore=tests/integration/test_sse.py \
        --ignore=tests/unit/test_interfaces.py \
        --ignore=tests/unit/test_types.py \
        --ignore=tests/unit/test_transport/test_sse.py

[group('validate')]
ci-local-recall-gates runs="3" warm_runs="1" query="x" limit="2" report_dir=".run/reports/knowledge-recall-perf":
    @bash scripts/ci-local-recall-gates.sh "{{runs}}" "{{warm_runs}}" "{{query}}" "{{limit}}" "{{report_dir}}"

[group('validate')]
test-contract-freeze:
    @bash scripts/ci-contract-freeze.sh

[group('validate')]
benchmark-wendao-search query="architecture" runs="5" warm_runs="2":
    @bash scripts/benchmark_wendao_search.sh "{{query}}" "{{runs}}" "{{warm_runs}}" debug no-build

[group('validate')]
benchmark-wendao-search-build query="architecture" runs="5" warm_runs="2":
    @bash scripts/benchmark_wendao_search.sh "{{query}}" "{{runs}}" "{{warm_runs}}" debug build

[group('validate')]
benchmark-wendao-search-release query="architecture" runs="5" warm_runs="2":
    @bash scripts/benchmark_wendao_search.sh "{{query}}" "{{runs}}" "{{warm_runs}}" release no-build

[group('validate')]
benchmark-wendao-search-release-build query="architecture" runs="5" warm_runs="2":
    @bash scripts/benchmark_wendao_search.sh "{{query}}" "{{runs}}" "{{warm_runs}}" release build

[group('validate')]
test-skills:
    @echo "Running skill tests via omni skill test --all..."
    @uv run omni skill test --all

# Run Rust MCP client integration test (requires MCP server: omni mcp --transport sse --port 3002)
test-mcp-integration:
    OMNI_MCP_URL=http://127.0.0.1:3002/sse cargo test -p omni-mcp-client --test streamable_http_integration -- --ignored

[group('validate')]
test-parallel:
    @echo "Running tests in parallel (faster)..."
    @uv run pytest packages/python/foundation/tests/ packages/python/core/tests/ packages/python/agent/tests/unit/cli/ -n auto --tb=short
    @cd packages/python/mcp-server && uv run pytest tests/ -n auto --tb=short --ignore=tests/integration/test_sse.py \
        --ignore=tests/unit/test_interfaces.py \
        --ignore=tests/unit/test_types.py \
        --ignore=tests/unit/test_transport/test_sse.py

[group('validate')]
vulture:
    @echo "Checking for dead code with vulture..."
    @uvx vulture || echo "Dead code detected - review above items"

[group('validate')]
test-stress:
    @echo "Running stress tests (slow)..."
    @uv run pytest packages/python/agent/tests/stress_tests/ -v

# Contract tests: data interface shape for run_skill, reindex, sync, run_entry (no xdist)
[group('validate')]
test-contracts:
    @echo "Running data interface contract tests..."
    @uv run pytest packages/python/agent/tests/contracts/ -v --tb=short --override-ini addopts="-v --tb=short"

# Scale benchmarks: in test-kit (run_skill, reindex_status, sync; latency thresholds)
[group('validate')]
test-benchmarks:
    @echo "Running scale benchmarks (omni-test-kit)..."
    @cd packages/python/test-kit && uv run pytest tests/benchmarks/ -v --tb=short

# ==============================================================================
# CHANGELOG MANAGEMENT
# =============================================================================

[group('changelog')]
changelog-preview:
    @echo "Changelog Preview (since last tag)"
    @echo "===================================="
    @cog log
    @echo ""
    @echo "Commit breakdown:"
    @cog log | grep -oE "^(feat|fix|docs|style|refactor|perf|test|build|ci|chore)" | sort | uniq -c

[group('changelog')]
changelog-stats:
    @echo "Changelog Statistics"
    @echo "===================="
    @echo "Commits by type:"
    @cog log | grep -oE "^(feat|fix|docs|style|refactor|perf|test|build|ci|chore)" | sort | uniq -c | sort -rn
    @echo ""
    @echo "Commits by author:"
    @git log --format='%an' $(git describe --tags --abbrev=0 2>/dev/null || echo "HEAD")..HEAD | sort | uniq -c | sort -rn
    @echo ""
    @echo "Changes since last release:"
    @git diff --stat $(git describe --tags --abbrev=0 2>/dev/null || echo "HEAD")..HEAD

[group('validate')]
check-commits:
    @echo "Validating commit messages..."
    @cog check

[group('validate')]
check-commits-range from to:
    @cog check --from {{from}} --to {{to}}

[group('changelog')]
changelog:
    @echo "Generating changelog..."
    @cog changelog

[group('changelog')]
changelog-at version:
    @cog changelog --at {{version}}

[group('changelog')]
changelog-export version="latest":
    #!/usr/bin/env bash
    set -euo pipefail
    VERSION={{version}}
    if [ "$VERSION" = "latest" ]; then
        VERSION=$(git describe --tags --abbrev=0 2>/dev/null || echo "v0.0.0")
    fi
    echo "Exporting changelog for $VERSION..."
    cog changelog --at "$VERSION" > "CHANGELOG_${VERSION}.md"
    echo "  Markdown: CHANGELOG_${VERSION}.md"
    cog log --format json > "CHANGELOG_${VERSION}.json"
    echo "  JSON: CHANGELOG_${VERSION}.json"
    cog changelog --at "$VERSION" | sed 's/\[//' | sed 's/\](.*)$//' > "CHANGELOG_${VERSION}.txt"
    echo "  Plain text: CHANGELOG_${VERSION}.txt"

# ==============================================================================
# VERSION MANAGEMENT & RELEASES
# ==============================================================================

[group('version')]
version:
    @echo "Current version: $(cat VERSION 2>/dev/null || git describe --tags --abbrev=0 2>/dev/null || echo 'No version found')"

[group('version')]
bump-auto: validate
    @echo "Auto-bumping version..."
    @cog bump --auto
    @just _sync-versions

[group('version')]
bump-patch: validate
    @echo "Bumping patch version..."
    @cog bump --patch
    @just _sync-versions

[group('version')]
bump-minor: validate
    @echo "Bumping minor version..."
    @cog bump --minor
    @just _sync-versions

[group('version')]
bump-major: validate
    @echo "Bumping major version..."
    @cog bump --major
    @just _sync-versions

# Sync versions across all packages from VERSION file
# Internal helper - called by bump-*
[private]
_sync-versions:
    #!/usr/bin/env bash
    set -euo pipefail
    NEW_VERSION=$(cat VERSION)
    echo "Syncing version $NEW_VERSION across all packages..."
    # Update agent pyproject.toml
    sed -i.bak "s/^version = \".*\"/version = \"$NEW_VERSION\"/" packages/python/agent/pyproject.toml && rm -f packages/python/agent/pyproject.toml.bak
    echo "  âœ“ Agent: packages/python/agent/pyproject.toml"
    # Update core pyproject.toml
    sed -i.bak "s/^version = \".*\"/version = \"$NEW_VERSION\"/" packages/python/core/pyproject.toml && rm -f packages/python/core/pyproject.toml.bak
    echo "  âœ“ Core: packages/python/core/pyproject.toml"
    # Update foundation pyproject.toml
    sed -i.bak "s/^version = \".*\"/version = \"$NEW_VERSION\"/" packages/python/foundation/pyproject.toml && rm -f packages/python/foundation/pyproject.toml.bak
    echo "  âœ“ Foundation: packages/python/foundation/pyproject.toml"
    # Update mcp-server pyproject.toml
    sed -i.bak "s/^version = \".*\"/version = \"$NEW_VERSION\"/" packages/python/mcp-server/pyproject.toml && rm -f packages/python/mcp-server/pyproject.toml.bak
    echo "  âœ“ MCP Server: packages/python/mcp-server/pyproject.toml"
    # Note: Root pyproject.toml uses dynamic version (hatch-vcs), no sync needed
    echo ""
    echo "All packages updated to version $NEW_VERSION!"

[group('version')]
bump-dry:
    @echo "Previewing version bump (dry run)..."
    @cog bump --auto --dry-run

[group('version')]
bump-pre type="alpha":
    @echo "Creating pre-release ({{type}})..."
    @cog bump --pre {{type}}

# Set explicit version across all packages
# Usage: just bump-set 0.3.0
[group('version')]
bump-set version:
    #!/usr/bin/env bash
    set -euo pipefail
    NEW_VERSION="{{version}}"
    echo "Setting version to $NEW_VERSION across all packages..."
    # Update VERSION file
    echo "$NEW_VERSION" > VERSION
    # Sync to all pyproject.toml files
    just _sync-versions
    echo ""
    echo "Next steps:"
    echo "  1. Run: git add -A && git commit -m 'chore: bump version to $NEW_VERSION'"
    echo "  2. Run: git tag v$NEW_VERSION"
    echo "  3. Run: git push origin main v$NEW_VERSION"

[group('version')]
release-notes version="latest":
    #!/usr/bin/env bash
    set -euo pipefail
    VERSION={{version}}
    if [ "$VERSION" = "latest" ]; then
        VERSION=$(git describe --tags --abbrev=0)
    fi
    echo "# Release $VERSION"
    echo ""
    cog changelog --at "$VERSION" | sed -n "/^## \[v${VERSION#v}\]/,/^## \[v/p" | sed '$d'
    echo ""
    echo "---"
    echo "**Full Changelog**: https://github.com/tao3k/omni-dev-fusion/compare/$(git describe --tags --abbrev=0 $VERSION^ 2>/dev/null)...$VERSION"

[group('version')]
publish-release version="latest":
    #!/usr/bin/env bash
    set -euo pipefail
    VERSION={{version}}
    if [ "$VERSION" = "latest" ]; then
        VERSION=$(git describe --tags --abbrev=0)
    fi
    NOTES=$(mktemp)
    just release-notes "$VERSION" > "$NOTES"
    echo "Publishing release $VERSION to GitHub..."
    gh release create "$VERSION" --title "Release $VERSION" --notes-file "$NOTES" --verify-tag
    rm -f "$NOTES"
    echo "Published release $VERSION"

[group('version')]
release type="auto":
    @echo "Starting release workflow..."
    @just bump-{{type}}
    @just publish-release

# ==============================================================================
# GIT OPERATIONS
# ==============================================================================

[group('git')]
status:
    @echo "Repository Status"
    @echo "=================="
    @git status
    @echo ""
    @echo "Branch: $(git branch --show-current)"
    @echo "Last commit: $(git log -1 --oneline)"
    @echo "Last tag: $(git describe --tags --abbrev=0 2>/dev/null || echo 'No tags')"

[group('git')]
log n="10":
    @cog log --no-pager | head -n {{n}}

# ==============================================================================
# DEVELOPMENT HELPERS
# ==============================================================================

[group('dev')]
fmt:
    @echo "Formatting code..."
    @lefthook run pre-commit --all-files

[group('dev')]
fmt-py:
    @echo "Formatting Python with ruff..."
    @uvx ruff format packages/python/

[group('dev')]
clean:
    @echo "Cleaning generated files..."
    @rm -f CHANGELOG_*.md CHANGELOG_*.json CHANGELOG_*.txt RELEASE_NOTES_*.md
    @echo "Cleaned"

[group('dev')]
update:
    @echo "Updating dependencies..."
    @devenv update
    @echo "Updated"

[group('dev')]
info:
    @echo "Environment Information"
    @echo "======================"
    @echo "devenv version: $(devenv version)"
    @echo "nix version: $(nix --version)"
    @echo "just version: $(just --version)"
    @echo "cog version: $(cog --version 2>/dev/null || echo 'not found')"
    @echo "git version: $(git --version)"
    @echo ""
    @echo "Repository: $(git remote get-url origin 2>/dev/null || echo 'no remote')"
    @echo "Branch: $(git branch --show-current)"
    @echo "Version: $(cat VERSION 2>/dev/null || git describe --tags --abbrev=0 2>/dev/null || echo 'unknown')"

[group('dev')]
watch:
    @echo "Watching for changes..."
    @watchexec -e nix,md,sh -c "just check-format"

# ==============================================================================
# MCP SERVER COMMANDS
# ==============================================================================

[group('mcp')]
debug server="packages/python/agent/src/agent/main.py":
    @echo "Starting MCP Inspector..."
    @uv run mcp-inspector python {{server}}

[group('mcp')]
run server="packages/python/agent/src/agent/main.py":
    @echo "Running MCP server: {{server}}"
    @python {{server}}

# ==============================================================================
# SRE HEALTH CHECKS
# Outputs machine-parseable JSON for AI agents and CI/CD
# ==============================================================================

[group('sre')]
health: health-git health-nix health-secrets health-devenv
    @echo ""
    @echo "Health check complete!"

# Git repository health (JSON optional)
[group('sre')]
health-git:
    #!/usr/bin/env bash
    set -euo pipefail
    if [ "${JUST_JSON:-}" = "true" ]; then
        BRANCH=$(git branch --show-current)
        UNCOMMITTED=$(git status --porcelain | wc -l)
        LAST_COMMIT=$(git log -1 --oneline)
        BEHIND=0
        git fetch --quiet 2>/dev/null && BEHIND=$(git log HEAD..origin/$BRANCH 2>/dev/null | wc -l)
        jq -n --arg branch "$BRANCH" --argjson uncommitted "$UNCOMMITTED" --arg last_commit "$LAST_COMMIT" --argjson behind "$BEHIND" \
            '{component: "git", branch: $branch, uncommitted_files: $uncommitted, last_commit: $last_commit, commits_behind: $behind}'
    else
        echo "Git Health"
        echo "=========="
        echo "Branch: $(git branch --show-current)"
        echo "Status: $(git status --porcelain | wc -l) uncommitted files"
        echo "Last commit: $(git log -1 --oneline)"
    fi

# Nix/Devenv health
[group('sre')]
health-nix:
    #!/usr/bin/env bash
    set -euo pipefail
    if [ "${JUST_JSON:-}" = "true" ]; then
        NIX_VERSION=$(nix --version 2>/dev/null || echo "")
        jq -n --arg version "$NIX_VERSION" '{component: "nix", version: $version}'
    else
        echo "Nix Health"
        echo "=========="
        echo "Nix version: $(nix --version)"
    fi

# Devenv health
[group('sre')]
health-devenv:
    #!/usr/bin/env bash
    set -euo pipefail
    if [ "${JUST_JSON:-}" = "true" ]; then
        VERSION=$(devenv version 2>/dev/null || echo "")
        NIXPKGS=$(devenv nixpkgs-version 2>/dev/null || echo "")
        jq -n --arg version "$VERSION" --arg nixpkgs "$NIXPKGS" '{component: "devenv", version: $version, nixpkgs: $nixpkgs}'
    else
        echo "Devenv Health"
        echo "============="
        echo "Version: $(devenv version 2>/dev/null || echo 'not found')"
        echo "Nixpkgs: $(devenv nixpkgs-version 2>/dev/null || echo 'unknown')"
    fi

# Secrets health check (validates presence, never echoes values)
[group('sre')]
health-secrets:
    #!/usr/bin/env bash
    set -euo pipefail
    MISSING=""
    if [ -z "${MINIMAX_API_KEY:-}" ]; then
        MISSING="MINIMAX_API_KEY"
    fi
    if [ "${JUST_JSON:-}" = "true" ]; then
        if [ -z "$MISSING" ]; then
            jq -n '{component: "secrets", status: "pass", message: "All required secrets present"}'
        else
            jq -n --arg missing "$MISSING" \
                '{component: "secrets", status: "fail", message: "Missing secrets", missing_keys: [$missing]}'
            exit 1
        fi
    else
        echo "Secrets Health"
        echo "=============="
        echo "Provider: dotenv"
        if [ -z "$MISSING" ]; then
            echo "Status: OK"
        else
            echo "Status: MISSING - $MISSING"
        fi
    fi

# API keys health (presence check only)
[group('sre')]
health-api-keys:
    #!/usr/bin/env bash
    set -euo pipefail
    if [ "${JUST_JSON:-}" = "true" ]; then
        if [ -n "${MINIMAX_API_KEY:-}" ]; then
            jq -n '{component: "api_keys", minimax: "present"}'
        else
            jq -n '{component: "api_keys", minimax: "missing"}'
            exit 1
        fi
    else
        echo "API Keys Health"
        echo "==============="
        if [ -n "${MINIMAX_API_KEY:-}" ]; then
            echo "MINIMAX_API_KEY: Set"
        else
            echo "MINIMAX_API_KEY: Not set"
        fi
    fi

# Composite health report for agents
[group('sre')]
health-report:
    #!/usr/bin/env bash
    set -euo pipefail
    JUST_JSON=true just health-git
    JUST_JSON=true just health-devenv
    JUST_JSON=true just health-secrets

# ==============================================================================
# CI/CD COMMANDS
# ==============================================================================

[group('ci')]
ci: validate changelog-preview
    @echo "CI checks passed!"

[group('ci')]
pre-release: validate changelog-preview changelog-stats
    @echo ""
    @echo "Pre-release checks complete!"
    @echo ""
    @echo "Next steps:"
    @echo "  1. Review changelog preview"
    @echo "  2. Run: just bump-auto (or bump-patch/minor/major)"
    @echo "  3. Run: just publish-release"

# ==============================================================================
# SECRET MANAGEMENT (secretspec)
# ==============================================================================

[group('secrets')]
secrets-check:
    @echo "Checking secrets status..."
    @secretspec check --profile development

[group('secrets')]
secrets-info:
    @echo "Secret Management Info"
    @echo "======================"
    @echo "Provider: dotenv"
    @echo "Profile: development"
    @echo ""
    @echo "Configured secrets:"
    @secretspec check --profile development | grep -E "^\s+[A-Z]" || echo "  (none)"

[group('secrets')]
secrets-set-minimax:
    #!/usr/bin/env bash
    set -euo pipefail
    read -p "Enter MINIMAX_API_KEY: " -s API_KEY
    echo
    secretspec set MINIMAX_API_KEY --value "$API_KEY" --profile development
    echo "MINIMAX_API_KEY set"

[group('secrets')]
secrets-get-minimax:
    @secretspec get MINIMAX_API_KEY

# ==============================================================================
# DOCUMENTATION
# ==============================================================================

[group('docs')]
docs:
    @echo "Documentation Index"
    @echo "==================="
    @echo ""
    @echo "Available documentation:"
    @ls -1 *.md | sed 's/^/  - /'

[group('docs')]
examples:
    @echo "Commit Message Examples"
    @echo "======================="
    @echo ""
    @echo "feat: add new feature"
    @echo "feat(cli): add command"
    @echo "fix: correct bug"
    @echo "docs: update documentation"
    @echo "refactor: reorganize code"
    @echo "chore: maintenance tasks"
    @echo ""
    @echo "feat(api)!: breaking change"
    @echo "BREAKING CHANGE: description"

# ==============================================================================
# SPEC KIT (Spec-Driven Development)
# ==============================================================================

[group('spec')]
spec-list:
    @echo "Available Specs"
    @echo "================"
    @ls -1 assets/specs/*.md 2>/dev/null | sed 's|^assets/specs/||' | sed 's/\.md$//' | sed 's/^/  - /' || echo "  No specs found"

[group('spec')]
spec-template:
    @echo "Spec Template"
    @echo "============="
    @cat assets/specs/TEMPLATE.md

[group('spec')]
archive spec_path target_category="explanation":
    #!/usr/bin/env bash
    set -euo pipefail
    if [ -z "{{spec_path}}" ]; then
        echo "Usage: just archive <spec-path> [category]"
        echo "Example: just archive assets/specs/auth_module.md explanation"
        exit 1
    fi
    if [ ! -f "{{spec_path}}" ]; then
        echo "Error: Spec '{{spec_path}}' not found"
        exit 1
    fi
    echo "============================================"
    echo "ðŸ“¦ Archiving completed spec..."
    echo "============================================"
    echo "Spec: {{spec_path}}"
    echo "Category: {{target_category}}"
    echo ""
    echo "Ask the Agent to archive:"
    echo ""
    echo "  @omni-orchestrator archive_spec_to_doc spec_path=\"{{spec_path}}\" target_category=\"{{target_category}}\""
    echo ""
    echo "============================================"

# ==============================================================================
# ALIASES (using recipe definitions instead of variable assignments)
# ==============================================================================

check: validate
cl: changelog-preview
c: commit
s: status
ship: release

# Compatibility aliases for agent-* pattern
agent-ci: agent-validate
agent-test: test
agent-lint: lint
agent-format: fmt

# ==============================================================================
# RUST BUILD
# ==============================================================================

# ==============================================================================
# TELEGRAM CHANNEL
# ==============================================================================

# Run Telegram channel in polling mode (no tunnel needed; for local testing).
# Bootstraps local Valkey automatically before starting the agent.
# Usage: TELEGRAM_BOT_TOKEN=xxx just agent-channel [valkey_port]
[group('channel')]
agent-channel valkey_port="6379":
    bash scripts/channel/agent-channel-polling.sh "{{valkey_port}}"

# Run Telegram channel in webhook mode via modular script entrypoint.
# Usage: TELEGRAM_BOT_TOKEN=xxx just agent-channel-webhook [valkey_port]
# Requires: ngrok installed, TELEGRAM_BOT_TOKEN in env, valkey-server in PATH
# Note: defaults to verbose debug logs (`--verbose`, `RUST_LOG=omni_agent=debug` when unset).
# Logs are mirrored to `${OMNI_CHANNEL_LOG_FILE:-.run/logs/omni-agent-webhook.log}` for black-box probes.
[group('channel')]
agent-channel-webhook valkey_port="6379":
    bash scripts/channel/agent-channel-webhook.sh "{{valkey_port}}"

# Black-box probe: inject one synthetic Telegram update into local webhook and wait for bot reply log.
# Usage: just agent-channel-blackbox "your prompt" [max_wait_secs]
# Behavior: event-driven by default (no hard timeout when max_wait_secs is omitted).
# Optional env: OMNI_TEST_CHAT_ID, OMNI_TEST_USER_ID, OMNI_TEST_USERNAME, OMNI_TEST_THREAD_ID, OMNI_WEBHOOK_URL,
#               OMNI_BLACKBOX_MAX_WAIT_SECS, OMNI_BLACKBOX_MAX_IDLE_SECS
# Advanced flags (expect/forbid regex, allow-no-bot, fail-fast tuning):
#   bash scripts/channel/agent-channel-blackbox.sh --help
# Implementation: Python (`scripts/channel/agent_channel_blackbox.py`) via shell wrapper.
[group('channel')]
agent-channel-blackbox prompt max_wait_secs="":
    if [ -n "{{max_wait_secs}}" ]; then \
        bash scripts/channel/agent-channel-blackbox.sh --prompt "{{prompt}}" --max-wait "{{max_wait_secs}}"; \
    else \
        bash scripts/channel/agent-channel-blackbox.sh --prompt "{{prompt}}"; \
    fi

# Run strict black-box command matrix with command-level event assertions.
# Usage: just agent-channel-blackbox-commands [max_wait_secs] [max_idle_secs]
# Optional env: OMNI_TEST_USERNAME, OMNI_TEST_CHAT_ID, OMNI_TEST_USER_ID, OMNI_TEST_THREAD_ID, OMNI_WEBHOOK_URL
[group('channel')]
agent-channel-blackbox-commands max_wait_secs="25" max_idle_secs="25":
    bash scripts/channel/test-omni-agent-command-events.sh --max-wait "{{max_wait_secs}}" --max-idle-secs "{{max_idle_secs}}"

# Run dedup black-box probe by posting the same update_id twice and asserting accepted/duplicate events.
# Usage: just agent-channel-blackbox-dedup [max_wait_secs]
# Optional env: OMNI_TEST_CHAT_ID, OMNI_TEST_USER_ID, OMNI_TEST_USERNAME, OMNI_WEBHOOK_URL
[group('channel')]
agent-channel-blackbox-dedup max_wait_secs="25":
    bash scripts/channel/test-omni-agent-dedup-events.sh --max-wait "{{max_wait_secs}}"

# Run concurrent dual-session black-box probe (same chat, different users).
# Usage: just agent-channel-blackbox-concurrent [max_wait_secs]
# Optional env: OMNI_TEST_CHAT_ID, OMNI_TEST_USER_ID, OMNI_TEST_USERNAME, OMNI_WEBHOOK_URL
[group('channel')]
agent-channel-blackbox-concurrent max_wait_secs="30":
    bash scripts/channel/test-omni-agent-concurrent-sessions.sh --max-wait "{{max_wait_secs}}"

# Capture and persist Telegram test-group mappings (for Test1/Test2/Test3 workflows).
# Usage:
#   just agent-channel-capture-groups
#   just agent-channel-capture-groups "Test1,Test2,Test3"
# Outputs:
#   .run/config/agent-channel-groups.json
#   .run/config/agent-channel-groups.env
[group('channel')]
agent-channel-capture-groups titles="Test1,Test2,Test3" log_file=".run/logs/omni-agent-webhook.log" output_json=".run/config/agent-channel-groups.json" output_env=".run/config/agent-channel-groups.env" user_id="":
    #!/usr/bin/env bash
    set -euo pipefail
    args=(--titles "{{titles}}" --log-file "{{log_file}}" --output-json "{{output_json}}" --output-env "{{output_env}}")
    if [ -n "{{user_id}}" ]; then
      args+=(--user-id "{{user_id}}")
    fi
    python3 scripts/channel/capture_telegram_group_profile.py "${args[@]}"

# Run end-to-end channel acceptance pipeline and emit one summary report.
# Pipeline:
#   capture-groups -> commands -> dedup -> concurrent -> matrix -> complex -> memory-evolution
# Usage:
#   just agent-channel-acceptance
# Reports:
#   .run/reports/agent-channel-acceptance.json
#   .run/reports/agent-channel-acceptance.md
[group('channel')]
agent-channel-acceptance max_wait_secs="40" max_idle_secs="25" evolution_max_wait_secs="90" evolution_max_idle_secs="60" evolution_max_parallel="4" titles="Test1,Test2,Test3" log_file=".run/logs/omni-agent-webhook.log" output_json=".run/reports/agent-channel-acceptance.json" output_markdown=".run/reports/agent-channel-acceptance.md" retries="2":
    bash scripts/channel/agent-channel-acceptance.sh "{{max_wait_secs}}" "{{max_idle_secs}}" "{{evolution_max_wait_secs}}" "{{evolution_max_idle_secs}}" "{{evolution_max_parallel}}" "{{titles}}" "{{log_file}}" "{{output_json}}" "{{output_markdown}}" "{{retries}}"

# Run session isolation matrix (concurrent baseline + cross reset/resume validation).
# Usage: just agent-channel-blackbox-matrix [max_wait_secs] [max_idle_secs]
# Advanced:
#   just agent-channel-blackbox-matrix 35 25 "-1002000000001" "-1002000000002" "1001" "1002" "1304799692" "1304799693" "Please reply ok"
# Reports:
#   .run/reports/agent-channel-session-matrix.json
#   .run/reports/agent-channel-session-matrix.md
[group('channel')]
agent-channel-blackbox-matrix max_wait_secs="35" max_idle_secs="25" chat_b="" chat_c="" thread_b="" thread_c="" user_b="" user_c="" mixed_plain_prompt="":
    #!/usr/bin/env bash
    set -euo pipefail
    args=(--max-wait "{{max_wait_secs}}" --max-idle-secs "{{max_idle_secs}}")
    if [ -n "{{chat_b}}" ]; then
      args+=(--chat-b "{{chat_b}}")
    fi
    if [ -n "{{chat_c}}" ]; then
      args+=(--chat-c "{{chat_c}}")
    fi
    if [ -n "{{thread_b}}" ]; then
      args+=(--thread-b "{{thread_b}}")
    fi
    if [ -n "{{thread_c}}" ]; then
      args+=(--thread-c "{{thread_c}}")
    fi
    if [ -n "{{user_b}}" ]; then
      args+=(--user-b "{{user_b}}")
    fi
    if [ -n "{{user_c}}" ]; then
      args+=(--user-c "{{user_c}}")
    fi
    if [ -n "{{mixed_plain_prompt}}" ]; then
      args+=(--mixed-plain-prompt "{{mixed_plain_prompt}}")
    fi
    bash scripts/channel/test-omni-agent-session-matrix.sh "${args[@]}"

# Run complex workflow black-box scenarios with dependency-graph complexity gates.
# Complexity is evaluated by workflow structure:
#   - step count
#   - dependency edges
#   - critical path length
#   - parallel wave count
# Usage:
#   just agent-channel-blackbox-complex
#   just agent-channel-blackbox-complex "scripts/channel/fixtures/complex_blackbox_scenarios.json" "" 40 30 4 14 14 6 3
# Reports:
#   .run/reports/agent-channel-complex-scenarios.json
#   .run/reports/agent-channel-complex-scenarios.md
[group('channel')]
agent-channel-blackbox-complex dataset="scripts/channel/fixtures/complex_blackbox_scenarios.json" scenario="" max_wait_secs="40" max_idle_secs="30" max_parallel="4" execute_wave_parallel="false" min_steps="14" min_dependency_edges="14" min_critical_path="6" min_parallel_waves="3" output_json=".run/reports/agent-channel-complex-scenarios.json" output_markdown=".run/reports/agent-channel-complex-scenarios.md":
    #!/usr/bin/env bash
    set -euo pipefail
    args=(--dataset "{{dataset}}" --max-wait "{{max_wait_secs}}" --max-idle-secs "{{max_idle_secs}}" --max-parallel "{{max_parallel}}" --min-steps "{{min_steps}}" --min-dependency-edges "{{min_dependency_edges}}" --min-critical-path "{{min_critical_path}}" --min-parallel-waves "{{min_parallel_waves}}" --min-error-signals "0" --min-negative-feedback-events "0" --min-correction-checks "0" --min-successful-corrections "0" --min-planned-hits "0" --min-natural-language-steps "0" --output-json "{{output_json}}" --output-markdown "{{output_markdown}}")
    if [ -n "{{scenario}}" ]; then
      args+=(--scenario "{{scenario}}")
    fi
    if [ "{{execute_wave_parallel}}" = "true" ]; then
      args+=(--execute-wave-parallel)
    fi
    bash scripts/channel/test-omni-agent-complex-scenarios.sh "${args[@]}"

# Run behavior-first memory evolution / self-correction black-box scenario.
# This suite validates:
#   - corrected memory persists across delayed turns
#   - feedback updates are observed in runtime logs
#   - cross-session distractors do not pollute target session memory
# Usage:
#   just agent-channel-blackbox-memory-evolution
# Reports:
#   .run/reports/agent-channel-memory-evolution.json
#   .run/reports/agent-channel-memory-evolution.md
[group('channel')]
agent-channel-blackbox-memory-evolution scenario="memory_self_correction_high_complexity_dag" max_wait_secs="80" max_idle_secs="60" max_parallel="4" execute_wave_parallel="false" output_json=".run/reports/agent-channel-memory-evolution.json" output_markdown=".run/reports/agent-channel-memory-evolution.md":
    #!/usr/bin/env bash
    set -euo pipefail
    args=(--dataset "scripts/channel/fixtures/memory_evolution_complex_scenarios.json" --scenario "{{scenario}}" --max-wait "{{max_wait_secs}}" --max-idle-secs "{{max_idle_secs}}" --max-parallel "{{max_parallel}}" --output-json "{{output_json}}" --output-markdown "{{output_markdown}}")
    if [ "{{execute_wave_parallel}}" = "true" ]; then
      args+=(--execute-wave-parallel)
    fi
    bash scripts/channel/test-omni-agent-complex-scenarios.sh "${args[@]}"

# Restart local MCP SSE server and wait for /health to become ready.
# Usage:
#   just mcp-restart
#   just mcp-restart 127.0.0.1 3002 false 25 .run/omni-mcp-sse.pid .run/logs/omni-mcp-sse.log
[group('channel')]
mcp-restart host="127.0.0.1" port="3002" no_embedding="false" health_timeout_secs="25" pid_file=".run/omni-mcp-sse.pid" log_file=".run/logs/omni-mcp-sse.log":
    #!/usr/bin/env bash
    set -euo pipefail
    args=(--host "{{host}}" --port "{{port}}" --health-timeout-secs "{{health_timeout_secs}}" --pid-file "{{pid_file}}" --log-file "{{log_file}}")
    if [ "{{no_embedding}}" = "true" ]; then
      args+=(--no-embedding)
    fi
    bash scripts/channel/restart-omni-mcp.sh "${args[@]}"

# Stress MCP startup by repeatedly launching omni-agent gateway probes.
# Usage:
#   just agent-channel-mcp-startup-stress
#   just agent-channel-mcp-startup-stress 8 4 50 0.2 ".mcp.json" "http://127.0.0.1:3002/health" "just mcp-restart" 0.2 true
# Reports:
#   .run/reports/omni-agent-mcp-startup-stress.json
#   .run/reports/omni-agent-mcp-startup-stress.md
[group('channel')]
agent-channel-mcp-startup-stress rounds="6" parallel="3" startup_timeout_secs="45" cooldown_secs="0.2" mcp_config=".mcp.json" health_url="http://127.0.0.1:3002/health" restart_mcp_cmd="" restart_mcp_settle_secs="2.0" strict_health_check="false" health_probe_interval_secs="0.2" health_probe_timeout_secs="1.0" output_json=".run/reports/omni-agent-mcp-startup-stress.json" output_markdown=".run/reports/omni-agent-mcp-startup-stress.md":
    #!/usr/bin/env bash
    set -euo pipefail
    args=(--rounds "{{rounds}}" --parallel "{{parallel}}" --startup-timeout-secs "{{startup_timeout_secs}}" --cooldown-secs "{{cooldown_secs}}" --mcp-config "{{mcp_config}}" --output-json "{{output_json}}" --output-markdown "{{output_markdown}}" --restart-mcp-settle-secs "{{restart_mcp_settle_secs}}" --health-probe-interval-secs "{{health_probe_interval_secs}}" --health-probe-timeout-secs "{{health_probe_timeout_secs}}")
    if [ -n "{{health_url}}" ]; then
      args+=(--health-url "{{health_url}}")
    fi
    if [ -n "{{restart_mcp_cmd}}" ]; then
      args+=(--restart-mcp-cmd "{{restart_mcp_cmd}}")
    fi
    if [ "{{strict_health_check}}" = "true" ]; then
      args+=(--strict-health-check)
    fi
    bash scripts/channel/test-omni-agent-mcp-startup-stress.sh "${args[@]}"

# Run MCP startup regression suite (hot + cold start).
# Usage:
#   just agent-channel-mcp-startup-suite
#   just agent-channel-mcp-startup-suite 20 8 8 4 60 0.2 127.0.0.1 3002 ".mcp.json" false false
#   just agent-channel-mcp-startup-suite 20 8 8 4 60 0.2 127.0.0.1 3002 ".mcp.json" false false 0 1200 1500 "" 0.5 0.5
# Reports:
#   .run/reports/omni-agent-mcp-startup-suite.json
#   .run/reports/omni-agent-mcp-startup-suite.md
[group('channel')]
agent-channel-mcp-startup-suite hot_rounds="20" hot_parallel="8" cold_rounds="8" cold_parallel="4" startup_timeout_secs="60" cooldown_secs="0.2" mcp_host="127.0.0.1" mcp_port="3002" mcp_config=".mcp.json" skip_hot="false" skip_cold="false" health_probe_interval_secs="0.2" health_probe_timeout_secs="1.0" quality_max_failed_probes="0" quality_max_hot_p95_ms="1200" quality_max_cold_p95_ms="1500" quality_min_health_samples="1" quality_max_health_failure_rate="0.02" quality_max_health_p95_ms="350" quality_baseline_json="" quality_max_hot_p95_regression_ratio="0.5" quality_max_cold_p95_regression_ratio="0.5":
    #!/usr/bin/env bash
    set -euo pipefail
    args=(--hot-rounds "{{hot_rounds}}" --hot-parallel "{{hot_parallel}}" --cold-rounds "{{cold_rounds}}" --cold-parallel "{{cold_parallel}}" --startup-timeout-secs "{{startup_timeout_secs}}" --cooldown-secs "{{cooldown_secs}}" --mcp-host "{{mcp_host}}" --mcp-port "{{mcp_port}}" --mcp-config "{{mcp_config}}" --health-probe-interval-secs "{{health_probe_interval_secs}}" --health-probe-timeout-secs "{{health_probe_timeout_secs}}" --quality-max-failed-probes "{{quality_max_failed_probes}}" --quality-max-hot-p95-ms "{{quality_max_hot_p95_ms}}" --quality-max-cold-p95-ms "{{quality_max_cold_p95_ms}}" --quality-min-health-samples "{{quality_min_health_samples}}" --quality-max-health-failure-rate "{{quality_max_health_failure_rate}}" --quality-max-health-p95-ms "{{quality_max_health_p95_ms}}" --quality-max-hot-p95-regression-ratio "{{quality_max_hot_p95_regression_ratio}}" --quality-max-cold-p95-regression-ratio "{{quality_max_cold_p95_regression_ratio}}")
    if [ -n "{{quality_baseline_json}}" ]; then
      args+=(--quality-baseline-json "{{quality_baseline_json}}")
    fi
    if [ "{{skip_hot}}" = "true" ]; then
      args+=(--skip-hot)
    fi
    if [ "{{skip_cold}}" = "true" ]; then
      args+=(--skip-cold)
    fi
    bash scripts/channel/test-omni-agent-mcp-startup-suite.sh "${args[@]}"

# Run memory-focused black-box + regression suite.
# Usage:
#   just test-omni-agent-memory-suite
#   just test-omni-agent-memory-suite full 30 30 tao3k true true redis://127.0.0.1:6379/0 false false false scripts/channel/fixtures/memory_evolution_complex_scenarios.json memory_self_correction_high_complexity_dag 1 "" ""
[group('channel')]
test-omni-agent-memory-suite suite="quick" max_wait_secs="25" max_idle_secs="25" username="" require_live_turn="false" with_valkey="false" valkey_url="redis://127.0.0.1:6379/0" skip_blackbox="false" skip_rust="false" skip_evolution="false" evolution_dataset="scripts/channel/fixtures/memory_evolution_complex_scenarios.json" evolution_scenario="memory_self_correction_high_complexity_dag" evolution_max_parallel="1" evolution_output_json="" evolution_output_markdown="":
    #!/usr/bin/env bash
    set -euo pipefail
    args=(--suite "{{suite}}" --max-wait "{{max_wait_secs}}" --max-idle-secs "{{max_idle_secs}}")
    if [ -n "{{username}}" ]; then
      args+=(--username "{{username}}")
    fi
    if [ "{{require_live_turn}}" = "true" ]; then
      args+=(--require-live-turn)
    fi
    if [ "{{with_valkey}}" = "true" ]; then
      args+=(--with-valkey --valkey-url "{{valkey_url}}")
    fi
    if [ "{{skip_blackbox}}" = "true" ]; then
      args+=(--skip-blackbox)
    fi
    if [ "{{skip_rust}}" = "true" ]; then
      args+=(--skip-rust)
    fi
    if [ "{{skip_evolution}}" = "true" ]; then
      args+=(--skip-evolution)
    fi
    if [ -n "{{evolution_dataset}}" ]; then
      args+=(--evolution-dataset "{{evolution_dataset}}")
    fi
    if [ -n "{{evolution_scenario}}" ]; then
      args+=(--evolution-scenario "{{evolution_scenario}}")
    fi
    if [ -n "{{evolution_max_parallel}}" ]; then
      args+=(--evolution-max-parallel "{{evolution_max_parallel}}")
    fi
    if [ -n "{{evolution_output_json}}" ]; then
      args+=(--evolution-output-json "{{evolution_output_json}}")
    fi
    if [ -n "{{evolution_output_markdown}}" ]; then
      args+=(--evolution-output-markdown "{{evolution_output_markdown}}")
    fi
    bash scripts/channel/test-omni-agent-memory-suite.sh "${args[@]}"

# Run memory A/B benchmark suite (baseline vs adaptive feedback).
# Usage:
#   just test-omni-agent-memory-benchmark
#   just test-omni-agent-memory-benchmark baseline 1 60 40 tao3k scripts/channel/fixtures/memory_benchmark_scenarios.json
[group('channel')]
test-omni-agent-memory-benchmark mode="both" iterations="1" max_wait_secs="40" max_idle_secs="30" username="" dataset="scripts/channel/fixtures/memory_benchmark_scenarios.json" output_json="" output_markdown="" skip_reset="false" fail_on_mcp_error="false" feedback_policy="deadband" feedback_down_threshold="0.34":
    #!/usr/bin/env bash
    set -euo pipefail
    args=(--iterations "{{iterations}}" --max-wait "{{max_wait_secs}}" --max-idle-secs "{{max_idle_secs}}" --dataset "{{dataset}}" --feedback-policy "{{feedback_policy}}" --feedback-down-threshold "{{feedback_down_threshold}}")
    if [ -n "{{username}}" ]; then
      args+=(--username "{{username}}")
    fi
    if [ "{{mode}}" = "baseline" ]; then
      args+=(--mode baseline)
    elif [ "{{mode}}" = "adaptive" ]; then
      args+=(--mode adaptive)
    elif [ "{{mode}}" != "both" ]; then
      echo "invalid mode: {{mode}} (expected: both|baseline|adaptive)" >&2
      exit 2
    fi
    if [ -n "{{output_json}}" ]; then
      args+=(--output-json "{{output_json}}")
    fi
    if [ -n "{{output_markdown}}" ]; then
      args+=(--output-markdown "{{output_markdown}}")
    fi
    if [ "{{skip_reset}}" = "true" ]; then
      args+=(--skip-reset)
    fi
    if [ "{{fail_on_mcp_error}}" = "true" ]; then
      args+=(--fail-on-mcp-error)
    fi
    bash scripts/channel/test-omni-agent-memory-benchmark.sh "${args[@]}"

# Aggregate evolution + benchmark + session matrix into one SLO gate report.
# Usage:
#   just test-omni-agent-memory-slo-report
#   just test-omni-agent-memory-slo-report .run/reports/omni-agent-memory-evolution.json .run/reports/omni-agent-memory-benchmark.json .run/reports/agent-channel-session-matrix.json .run/logs/omni-agent-webhook.log true
[group('channel')]
test-omni-agent-memory-slo-report evolution_report_json=".run/reports/omni-agent-memory-evolution.json" benchmark_report_json=".run/reports/omni-agent-memory-benchmark.json" session_matrix_report_json=".run/reports/agent-channel-session-matrix.json" runtime_log_file="" enable_stream_gate="false" output_json=".run/reports/omni-agent-memory-slo-report.json" output_markdown=".run/reports/omni-agent-memory-slo-report.md":
    bash scripts/channel/test-omni-agent-memory-slo-report.sh "{{evolution_report_json}}" "{{benchmark_report_json}}" "{{session_matrix_report_json}}" "{{runtime_log_file}}" "{{enable_stream_gate}}" "{{output_json}}" "{{output_markdown}}"

# Start local Valkey daemon for webhook dedup / stress tests.
# Usage: just valkey-start [port]
[group('channel')]
valkey-start port="6379":
    bash scripts/channel/valkey-start.sh "{{port}}"

# Stop local Valkey daemon started by `just valkey-start`.
# Usage: just valkey-stop [port]
[group('channel')]
valkey-stop port="6379":
    bash scripts/channel/valkey-stop.sh "{{port}}"

# Show local Valkey status for a given port.
# Usage: just valkey-status [port]
[group('channel')]
valkey-status port="6379":
    bash scripts/channel/valkey-status.sh "{{port}}"

# Run ignored omni-agent stress tests that require live Valkey.
# Usage: just test-omni-agent-valkey-stress [valkey_url]
[group('channel')]
test-omni-agent-valkey-stress valkey_url="redis://127.0.0.1:6379/0":
    bash scripts/channel/test-omni-agent-valkey-stress.sh "{{valkey_url}}"

# Run focused distributed SessionGate verification against live Valkey.
# Usage: just test-omni-agent-valkey-session-gate [valkey_url]
[group('channel')]
test-omni-agent-valkey-session-gate valkey_url="redis://127.0.0.1:6379/0":
    bash scripts/channel/test-omni-agent-valkey-session-gate.sh "{{valkey_url}}"

# Run focused cross-instance session-context restore verification against live Valkey.
# Usage: just test-omni-agent-valkey-session-context [valkey_url]
[group('channel')]
test-omni-agent-valkey-session-context valkey_url="redis://127.0.0.1:6379/0":
    bash scripts/channel/test-omni-agent-valkey-session-context.sh "{{valkey_url}}"

# Run focused multi-HTTP Valkey dedup verification.
# Usage: just test-omni-agent-valkey-multi-http [valkey_url]
[group('channel')]
test-omni-agent-valkey-multi-http valkey_url="redis://127.0.0.1:6379/0":
    bash scripts/channel/test-omni-agent-valkey-multi-http.sh "{{valkey_url}}"

# Run focused multi-process Valkey dedup verification.
# Usage: just test-omni-agent-valkey-multi-process [valkey_url]
[group('channel')]
test-omni-agent-valkey-multi-process valkey_url="redis://127.0.0.1:6379/0":
    bash scripts/channel/test-omni-agent-valkey-multi-process.sh "{{valkey_url}}"

# Run full live Valkey webhook verification suite
# (stress + distributed session gate + session-context + multi-http + multi-process).
# Usage: just test-omni-agent-valkey-full [valkey_url]
[group('channel')]
test-omni-agent-valkey-full valkey_url="redis://127.0.0.1:6379/0":
    bash scripts/channel/test-omni-agent-valkey-full.sh "{{valkey_url}}"

# Validate observability event sequence from a captured agent log file.
# Usage:
#   just check-omni-agent-event-sequence <log_file>
#   just check-omni-agent-event-sequence <log_file> true true valkey
[group('channel')]
check-omni-agent-event-sequence log_file strict="false" require_memory="false" expect_memory_backend="":
    #!/usr/bin/env bash
    set -euo pipefail
    args=()
    if [ "{{strict}}" = "true" ]; then
      args+=(--strict)
    fi
    if [ "{{require_memory}}" = "true" ]; then
      args+=(--require-memory)
    fi
    if [ -n "{{expect_memory_backend}}" ]; then
      args+=(--expect-memory-backend "{{expect_memory_backend}}")
    fi
    bash scripts/channel/check-omni-agent-event-sequence.sh "{{log_file}}" "${args[@]}"

# ==============================================================================
# RUST BUILD
# ==============================================================================

[group('rust')]
build-rust:
    #!/usr/bin/env bash
    set -euo pipefail

    echo "ðŸ”¨ Building Rust core library..."
    cd packages/rust/bindings/python

    # Build wheel (faster than maturin develop)
    echo "ðŸ“¦ Creating wheel..."
    maturin build --release

    # Find and install the wheel
    WHEEL_PATH=$(find ../../target/wheels -name "*.whl" 2>/dev/null | head -1)
    if [ -z "$WHEEL_PATH" ]; then
        echo "âŒ Error: Could not find built wheel"
        exit 1
    fi

    echo "ðŸ“¦ Installing wheel: $WHEEL_PATH"
    uv pip install --force-reinstall --no-deps "$WHEEL_PATH"

    echo "âœ… Rust library installed to venv"


[group('rust')]
build-rust-dev:
    #!/usr/bin/env bash
    set -euo pipefail

    echo "ðŸ”¨ Building Rust core library (DEBUG mode - fast)..."
    cd packages/rust/bindings/python

    # maturin develop uses debug build by default (much faster than release)
    # First cargo build, then install
    cargo build && maturin develop

    echo "âœ… Rust debug library installed to venv"


[group('rust')]
build-rust-wheel:
    #!/usr/bin/env bash
    set -euo pipefail

    echo "ðŸ“¦ Building Rust wheel (no recompile)..."
    cd packages/rust/bindings/python

    # Only build wheel (assumes cargo build --release already done)
    maturin build --release --skip-auditwheel

    # Find and show the wheel
    WHEEL_PATH=$(find ../../target/wheels -name "*.whl" 2>/dev/null | head -1)
    if [ -n "$WHEEL_PATH" ]; then
        echo "âœ… Wheel: $WHEEL_PATH"
        ls -lh "$WHEEL_PATH"
    else
        echo "âŒ Error: Could not find built wheel"
        exit 1
    fi
