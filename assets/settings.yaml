# assets/settings.yaml
# Project Settings - Configuration File Paths
#
# This file centralizes paths to configuration files.
# Use --conf flag to override the configuration directory (default: ./assets)
#
# Usage:
#   python script.py --conf ./assets
#
#   from common.settings import get_setting
#   cog_path = get_setting("config.cog_toml")
#
# Note: Actual commit types/scopes are read from cog.toml/.conform.yaml,
# not from this file. This file only defines the paths to those files.

# =============================================================================
# Configuration Directory
# =============================================================================
# Root directory for all agent-related configurations
# Override with: --conf /path/to/conf

conf_dir: "assets"

# =============================================================================
# Asset Directories (Migration: agent/ -> assets/)
# =============================================================================
# All paths are relative to project root
assets:
  # Skills directory
  skills_dir: "assets/skills"

  # Templates directory (Cascading template loading)
  # User overrides > Skill defaults pattern
  templates_dir: "assets/templates"

  # Knowledge base (RAG documents)
  knowledge_dir: "assets/knowledge"

  # How-to guides
  howto_dir: "assets/how-to"

  # Specifications
  specs_dir: "assets/specs"
  specs_archive_dir: "assets/specs.archive"
  specs_template: "assets/specs/template.md"

  # Standards and guidelines
  standards_dir: "assets/standards"

  # Writing style
  writing_style_dir: "assets/writing-style"

  # Core prompts
  prompts_dir: "assets/prompts"

  # Repomix cache
  cache_dir: ".cache"

# =============================================================================
# Configuration Files
# =============================================================================
config:
  # Commit message validation configuration files
  cog_toml: "cog.toml"
  conform_yaml: ".conform.yaml"
  lefhook_yaml: "lefthook.yml"
  # Project root marker
  project_marker: ".git"

# =============================================================================
# API Key Configuration
# =============================================================================
# API key files - paths relative to project root (git toplevel)
api:
  # Anthropic API key configuration file
  anthropic_settings: ".claude/settings.json"

# =============================================================================
# Inference Configuration (LLM API)
# =============================================================================
# Configure which LLM provider to use for internal inference (writer, semantic search, etc.)
inference:
  # Environment variable name for the API key
  # Common options: ANTHROPIC_API_KEY, MINIMAX_API_KEY, OPENAI_API_KEY
  api_key_env: "MINIMAX_API_KEY"

  # API base URL (for OpenAI-compatible or Anthropic-compatible endpoints)
  base_url: "https://api.minimax.io/anthropic"

  # Default model name
  model: "MiniMax-M2.1"

  # Request timeout in seconds
  timeout: 120

  # Max tokens per response
  max_tokens: 4096

# =============================================================================
# MCP Configuration
# =============================================================================
# MCP configuration files
mcp:
  # Main MCP configuration file
  config_file: ".mcp.json"

  # Server names
  orchestrator: "orchestrator"
  coder: "coder"
  executor: "executor"

  # Default timeout (seconds)
  timeout: 120

# =============================================================================
# Git Commit Settings
# =============================================================================
# Note: Actual types and scopes are loaded from cog.toml/.conform.yaml
# These are fallback values only when config files don't exist

commit:
  # Default protocol: "stop_and_ask" or "auto_commit"
  protocol: "stop_and_ask"

# =============================================================================
# Logging Settings
# =============================================================================
logging:
  format: "json"
  level: "info"

# =============================================================================
# Configuration-Driven Context
# =============================================================================
prompts:
  core_path: "assets/prompts/system_core.md"
  user_custom_path: ".cache/user_custom.md"

# =============================================================================
# Knowledge Ingestion Configuration
# =============================================================================
knowledge:
  # Knowledge base directory
  base_dir: "assets/knowledge"
  # How-to guides directory
  howto_dir: "assets/how-to"
  # Specific knowledge files
  gitops_file: "assets/how-to/gitops.md"
  gitops_cache: "assets/knowledge/gitops-cache.md"
  testing_workflows: "assets/how-to/testing-workflows.md"

# =============================================================================
# Standards and References
# =============================================================================
standards:
  # Feature lifecycle document
  feature_lifecycle: "assets/standards/feature-lifecycle.md"
  # Documentation workflow guide
  documentation_workflow: "assets/how-to/documentation-workflow.md"

# =============================================================================
# Spec Templates
# =============================================================================
specs:
  # Spec template file
  template: "assets/specs/template.md"
  # Example spec path for documentation
  example: "assets/specs/auth_module.md"

# =============================================================================
# Memory Configuration (The Hippocampus)
# =============================================================================
# Memory path follows prj-spec: {git_toplevel}/.cache/{project}/.memory/
# Override with custom path if needed
memory:
  # Custom memory path (leave empty to use default prj-spec)
  # path: "/custom/path/.memory"
  path: ""

# =============================================================================
# Checkpoint / Workflow State Configuration
# =============================================================================
# Unified checkpoint storage using Rust LanceDB backend
# All workflow state persists here - no separate SQLite per workflow

checkpoint:
  # LanceDB database path (relative to project root or absolute)
  # Default: .cache/checkpoints.lance (LanceDB format)
  db_path: ".cache/checkpoints.lance"

  # Table prefix for different workflow types
  # smart_commit -> table: checkpoint_smart_commit
  table_prefix: "checkpoint_"

  # Default dimension for embeddings (OpenAI text-embedding-3-small)
  embedding_dimension: 1536

# =============================================================================
# Cache Configuration
# =============================================================================
cache:
  # Project name for cache directory structure
  # All cache dirs will be under: {git_root}/.cache/{project_name}/
  project_name: "omni-dev-fusion"

# =============================================================================
# Skill Management
# =============================================================================
skills:
  # Skills to preload at server startup
  # NOTE: These are "Core" skills but can still be manually unloaded via skill.unload
  preload:
    - knowledge
    - memory
    - git
    - filesystem
    - writer
    - terminal
    - testing_protocol
    - code_tools
    - skill

  # LRU + TTL eviction settings
  ttl:
    timeout: 1800 # Skill eviction timeout in seconds (30 minutes)
    check_interval: 300 # TTL cleanup check interval (5 minutes)

  max_loaded: 15 # Maximum loaded skills limit

  # Reload behavior
  reload:
    # Allow LLM to reload skills via load_skill
    enabled: true
    # Default to false - require explicit confirmation
    auto_confirm: false

  # =============================================================================
  # Filter Commands from Core Tools
  # =============================================================================
  # Commands to FILTER from being in core tools.
  # Use Claude's native capabilities instead - MCP adds unnecessary latency.
  # These commands are still available via dynamic loading when explicitly needed.
  filter_commands:
    - "terminal.run_command" # Use Claude's native bash runner
    - "terminal.run_task" # Value not proven, use direct commands
    - "terminal.inspect_environment" # Use pwd/uname directly

  # =============================================================================
  # Dynamic Tool Loading Limits
  # =============================================================================
  limits:
    dynamic_tools: 100 # Max dynamic tools per request
    core_min: 3 # Minimum guaranteed tools
    rerank_threshold: 20 # If tools found > this, re-rank by score
    schema_cache_ttl: 300 # Tool schema cache TTL (seconds)
    auto_optimize: true # Enable automatic context optimization

  # =============================================================================
  # Skill Architecture Standards (ODF-EP v7.0)
  # =============================================================================
  # Defines the canonical structure for all Omni skills.
  # Aligned with Anthropic's Skill Standard but extended for Omni's MCP features.
  # Used by StructureValidator to enforce skill structure integrity.

  architecture:
    version: "v2.0"

    # Source of truth for skill definition
    definition_file: "SKILL.md"

    # Directory structure specification
    structure:
      # Required files for every skill (ODF-EP v7.0 Core)
      required:
        # Core definition (Trinity: State)
        - path: "SKILL.md"
          description: "Skill metadata (YAML frontmatter) and system prompts"
          type: "file"

      # Default files/directories (auto-generated if not exists)
      # Validation ignores these - they can exist or not
      default:
        - path: "scripts/"
          description: "Standalone executables (Python workflows, state management)"
          type: "dir"

        # Extensions directory: Stateful modules, lifecycle hooks, complex logic (Meta-Agent, Watchers)
        - path: "extensions/"
          description: "Internal modules and plugins (Meta-Agent, Factory, Watchers)"
          type: "dir"

        - path: "templates/"
          description: "Jinja2 templates for skill output (Cascading loader)"
          type: "dir"

        - path: "references/"
          description: "Markdown documentation for RAG ingestion"
          type: "dir"

        - path: "assets/"
          description: "Static resources, templates, guides"
          type: "dir"

        - path: "data/"
          description: "Data files (JSON, CSV, etc.) for skill operations"
          type: "dir"

        - path: "tests/"
          description: "Pytest tests specifically for this skill"
          type: "dir"

        - path: "repomix.json"
          description: "Repomix configuration (auto-generated if missing)"
          type: "file"

        # Sidecar Execution Pattern support
        - path: "pyproject.toml"
          description: "Skill dependencies for subprocess mode (crawl4ai, playwright, etc.)"
          type: "file"

        - path: "README.md"
          description: "Developer documentation (human-readable, not for LLM)"
          type: "file"

      # Optional structure examples (for documentation and validation)
      # These show common patterns but are not required
      optional:
        # Example: Cascading template structure
        - path: "templates/"
          description: "Skill-local Jinja2 templates (defaults)"
          example: |
            assets/skills/git/templates/
            ├── commit_message.j2
            ├── workflow_result.j2
            └── error_message.j2
          validation: "Optional - if present, enables cascading template loading"

        # Example: Scripts directory with atomic implementations
        - path: "scripts/"
          description: "Atomic implementations (Router-Controller pattern)"
          example: |
            assets/skills/git/scripts/
            ├── __init__.py
            ├── rendering.py    # Template rendering layer
            ├── workflow.py     # Git workflow logic
            └── status.py       # Git status implementation
          validation: "Optional - recommended for complex skills"

        # Example: User template overrides directory
        - path: "assets/templates/{skill}/"
          description: "User-level template overrides (cascading pattern)"
          example: |
            assets/templates/git/
            ├── commit_message.j2  # Overrides skill default
            └── workflow_result.j2
          validation: "Optional - if exists, takes precedence over skill defaults"

    # Jinja2 template configuration
    templates:
      # Centralized templates directory
      source_dir: "assets/templates/skill"

      # Auto-generate templates
      auto_generate:
        - source: "SKILL.md.j2"
          target: "SKILL.md"
        - source: "tools.py.j2"
          target: "tools.py"
        - source: "RAEDME.md.j2"
          target: "README.md"

    # Validation rules
    validation:
      # Block commit if skill structure is invalid
      block_on_invalid: true

      # Allow non-standard files (warning only)
      allow_ghost_files: false

      # Disallowed files (must not exist - causes LLM confusion)
      disallowed_files:
        - "manifest.json" # Redundant - metadata in SKILL.md YAML frontmatter
        - "prompts.md" # Redundant - prompts in SKILL.md body

  # =============================================================================
  # Configuration-Driven Tool Aliasing (Native Mimicry)
  # =============================================================================
  # Defines how skill commands are presented to Claude (aliasing and behavioral hints).
  # This enables "Configuration over Convention" - no Python code changes needed.
  #
  # Format:
  #   skill.command:
  #     alias: "native_name"          # Rename the tool (optional)
  #     append_doc: "..."             # Behavioral instructions (optional)
  #
  # The append_doc content is injected into the tool description and serves as
  # a context-embedded prompt that Claude reads when deciding which tool to use.

  overrides:
    # Web Fetching - Critical override to prevent curl/wget usage
    crawl4ai.crawl_webpage:
      alias: "web_fetch"
      append_doc: |

        ## ⚡️ OPERATIONAL RULE
        - **PRIMARY TOOL**: Use this tool for ALL web content retrieval.
        - **FORBIDDEN**: Do NOT use `curl`, `wget`, or shell requests.
        - **OUTPUT**: Returns structured Markdown, optimized for reading.

    # File Operations - Consolidated from file_ops
    filesystem.read_file:
      alias: "read_file"
      append_doc: "\n\nUse this instead of `cat` for safe file reading with line numbering."
    filesystem.write_file:
      alias: "write_file"
      append_doc: "\n\nUse this instead of `echo` or redirection for atomic file writes."
    filesystem.save_file:
      alias: "save_file"
      append_doc: "\n\nWrite with backup (.bak), syntax validation, and auto-writing-check."
    filesystem.search_files:
      alias: "search_files"
      append_doc: "\n\nUse this instead of `grep` for text search in files."
    filesystem.apply_changes:
      alias: "apply_changes"
      append_doc: "\n\n[BATCH] Apply multiple file operations in one call."
    filesystem.ast_search:
      alias: "ast_search"
      append_doc: "\n\nQuery code structure using ast-grep patterns."
    filesystem.ast_rewrite:
      alias: "ast_rewrite"
      append_doc: "\n\nApply AST-based code refactoring with ast-grep."

    # Terminal - Command execution
    terminal.run_task:
      alias: "run_command"
      append_doc: "\n\nUse this instead of raw Bash when you need stdout/stderr capture and error handling."

    # Git Operations - Structured output
    git.status:
      alias: "git_status"
      append_doc: "\n\nUse this instead of running `git status` in terminal for structured output."
    git.stage_all:
      alias: "git_stage"
      append_doc: "\n\nUse this to stage all changes before commit."
    git.commit:
      alias: "git_commit"
      append_doc: "\n\nUse this for structured commit messages. Requires message parameter."

    # Memory Operations
    memory.recall:
      alias: "search_memory"
      append_doc: "\n\nSemantic search across your project's memory/knowledge base."
    memory.remember_insight:
      alias: "save_memory"
      append_doc: "\n\nPersist important context for future sessions."

# =============================================================================
# Claude Code Symbiosis - Context Compression
# =============================================================================
# Settings for Dynamic Context Compression when injecting context to Claude Code
# Prevents context bloat by summarizing large RAG results

context_compression:
  # Enable/disable context compression globally
  enabled: true

  # Maximum context tokens before compression is triggered
  # Claude 3.5 Sonnet has ~200K context window, but we compress to save tokens
  max_context_tokens: 4000

  # Maximum file size (KB) before compression is triggered
  # Files larger than this will be summarized instead of fully included
  max_file_size_kb: 50

  # Compression method: "llm" (use LLM to summarize) or "truncate" (simple cut)
  method: "llm"

# =============================================================================
# Claude Code Symbiosis - Post-Mortem Audit
# =============================================================================
# Settings for automatic review after Claude Code execution

post_mortem:
  # Enable/disable Post-Mortem audit after Claude Code execution
  enabled: true

  # Confidence threshold: audits below this are flagged for manual review
  confidence_threshold: 0.8

# =============================================================================
# LLM Context Limits
# =============================================================================
context:
  max_schema_tokens: 4000 # Max tokens for tool schemas
  avg_schema_tokens: 250 # Est. tokens per tool schema

security:
  # Enable/disable security scanning (default: true)
  enabled: true

  # Thresholds for security decisions (0-100)
  # Score >= block_threshold: BLOCK the skill
  # Score >= warn_threshold: WARN user but allow
  block_threshold: 30
  warn_threshold: 10

  # Trusted sources (skip security scan for these)
  # Format: "github.com/username" or full repository URL patterns
  trusted_sources:
    - "github.com/omni-dev"
    - "github.com/trusted-org"

  # Sandbox configuration (future enhancement)
  sandbox:
    enabled: false
    timeout_seconds: 30
    memory_limit_mb: 128
